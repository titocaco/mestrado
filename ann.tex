% !TEX root = main.tex
\chapter{Redes Neurais Artificiais}
\label{cha:ann}


A história de \textbf{Redes Neurais Artificiais} começou em 1943 com a fundação do modelo matemático proposto em \citep{mcculloch1943logical}, que em 1951 permitiu abordagens inspiradas na biologia cerebral e aplicações em inteligência artificial \citep{kleene1951representation}, como no caso da criação do \textbf{Perceptron}\footnote{A menor unidade de processamento de uma rede neural, que pode fazer pequenos trabalhos de processamento por si só, mas pode cooperar com outros para alcançar uma convergência, mesmo para um trabalho enorme distribuído por um grande número de neurônios trabalhando em uma rede.} \citep{rosenblatt1958perceptron}, um algoritmo de classificação binária baseado no aprendizado supervisionado, um dos desenvolvimentos mais importantes no campo. Outro grande passo foi dado em 1967, quando foi publicado um trabalho sobre redes envolvendo múltiplas camadas \citep{ivakhnenko1967cybernetics}. A Seção \ref{sec:ann_perceptron} esclarecerá o funcionamento do Perceptron.

Alguns anos mais tarde, mais precisamente em 1972, dois grandes problemas foram identificados nos modelos de redes neurais então conhecidos: a incapacidade dos perceptrons básicos para processar operações de ``ou exclusivo'' (XOR) e a escassez de poder computacional exigido para se trabalhar com redes neurais de muitas camadas \citep{minsky1972perceptrons}. Estes problemas dificultaram muito para que houvesse qualquer avanço relevante nesta área durante vários anos, mas em 1975 foi proposto o \textbf{Backpropagation} \citep{werbos1975beyond}, um novo algoritmo que faria esta área de pesquisa continuar a ser interessante, uma vez que resolveria o problema de operação XOR e aceleraria o processamento em redes multi-camadas ajustando os pesos das camadas por meio de uma distribuição de erro. Uma explicação detalhada sobre Backpropagation será oferecida na Seção \ref{sec:ann_backpropagation}.

Considerando a alta demanda de poder computacional que tais modelos trouxeram consigo, pode-se dizer que muitos avanços na área foram conquistados nos anos seguintes, também por conta de trabalhos envolvendo paralelismo, por exemplo. \citep{rumelhart1986psychological}. Em 1993 algumas melhorias foram alcançadas em redes neurais \citep{180705}; e, em 2010, o uso de \textit{unidades de processamento gráfico}\footnote{Popularmente conhecidas como \textit{placa de vídeo}, que é um termo que, de modo geral, remete, mais espeicificamente, a placas dedicadas, com processador e memória próprios.} (\textbf{GPU}, \textit{Graphic Processing Unit}) na paralelização \citep{scherer2010evaluation} foi extremamente importante.

\nomenclature{GPU}{\textit{Graphic Processing Unit}}

Também em 2006, um modelo de representações de alto nível foi proposto usando camadas sucessivas de variáveis latentes com máquinas Boltzmann \citep{hinton2006fast}. E, ainda mais recentemente, em 2013, foi introduzida uma rede suficientemente avançada para reconhecer conceitos avançados, como gatos em vídeos do YouTube \citep{le2013building} de maneira não supervisionada. Essas implementações de um grande número de camadas passaram a incluir em sua nomenclatura o termo ``Deep'' e, portanto, o termo \textit{Deep Learning} tornou-se popular quando se refere a \textit{redes neurais profundas} (\textbf{DNN}, \textit{Deep Neural Networks}).

\nomenclature{DNN}{\textit{Deep Neural Networks}}

Atualmente, existem inúmeras aplicações de \textit{Deep Learning} para as mais diversas áreas de atividade, como neurociências \citep{Varatharajan2018}, \textit{internet das coisas} (\textbf{IoT}, \textit{Internet of Things}) \citep{8396317}, segurança redes de computadores \citep{8291134}, reconhecimento facial \citep{8253595}, instrumentação \citep{8319916}, telecomunicações \citep{8359094}, imageamento médico \citep{8359121}, detecção de objetos \citep{8253582} tratamento de distúrbios da voz \citep{8337897}, mobilidade \citep{8344803} e tantos outros.

\nomenclature{IoT}{\textit{Internet of Things}}


%   ----------------------
%   ----- Perceptron -----
%   ----------------------
\section{Perceptron}
\label{sec:ann_perceptron}

O \textit{Perceptron} é compreendido como a menor unidade neural capaz de realizar a tarefa de classificar dados linearmente separáveis, separando-os através de uma região fronteiriça denominada hiperplano\footnote{Hiperplano nada mais é do que a generalização de um plano para dimensões superiores; trata-se de uma forma geométrica com uma dimensão a menos que o hiperespaço, que é o caso que utiliza-se de todas as dimensões disponíveis}. O perceptron foi desenvolvido por Frank Rosenblatt \citep{rosenblatt1958perceptron}, enquanto trabalhava no \textit{Cornell Aeronautical Laboratory}, em um projeto financiado pelo \textit{Office of Naval Research}; e, diferentemente do que hoje se esperaria, teria sido originalmente planejado para ser uma máquina, não um programa de computador.

Em seu próprio trabalho original, Rosenblatt exibiu um esboço de como ele compreendia ser a organização do \textit{Perceptron}, bem como suas intraconexões, que envolviam componentes que ele chamou de Retina, Área de Projeção, Área de Associação e Respostas, como exibido na Figura \ref{fig:ann_perceptron_organization}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/ann_perceptron_original_organization.pdf}
    \caption{Organização de um \textit{Perceptron}, segundo \citep{rosenblatt1958perceptron}.}
    \label{fig:ann_perceptron_organization}
\end{figure}

A Retina trata-se do primeiro componente dessa arquitetura; e é composta por unidades sensoriais com um comportamento que Rosenblatt assumiu como sendo \textit{tudo ou nada}, que pode ser mapeado binariamente. Os impulsos coletados pelos sensores da retina são enviados às chamadas \textit{células de associação}, que se localizam na \textit{área de projeção} (representada na Figura \ref{fig:ann_perceptron_organization} pela região circular $A_{I}$), mas essa região não está presente em todos os modelos de organização; no caso de não estar presente, a conexão é feita de forma direta entre os sensores da retina e a \textit{área de associação} ($A_{II}$).

As unidades da \textit{área de projeção} podem receber estímulos oriundos dos sensores da retina que resultem em excitação ou em inibição. O próprio conceito por detrás do que é comumente chamado de \textit{função de ativação} foi trazido neste mesmo trabalho, dado que, segundo Rosenblatt, as unidades $A$ emitem uma saída\footnote{Para os propósitos de seu modelo, Rosenblatt considerou a saída como sendo unitária, embora reconheça a possibilidade de ser utilizada outra abordagem.} sempre que a soma de todas as entradas da unidade em questão resultar em um valor igual ou superior ao limiar $\theta$ definido. As conexões feitas entre as unidades da área de projeção ($A_{I}$) e as da área de associação ($A_{II}$) foram tratadas como aleatórias, assim sendo, apesar de haver conexões entre unidades das diferentes áreas, tais conexões não necessariamente respeitarão uma específica distribuição; além disso, vale ressaltar que as características e os comportamentos das unidades em si, independentemente de a qual região pertençam, são os mesmos.

A respeito das \textit{respostas} ($R_{1}, \dots, R_{n}$), que são descritas como células ou grupos de células, seu comportamento é similar ao das unidades $A$; suas conexões, contudo, são um tanto diferentes, dado que, apesar de também serem feitas aleatoriamente, são altamente numerosas e são bidirecionais, permitindo uma comunicação diferenciadas com as unidades da área de associação ($A_{II}$), havendo para cada resposta $R$ um \textit{conjunto de origem}\footnote{Em uma tradução livre do que originalmente fora chamado de \textit{source-set}.}, ou seja, um conjunto de unidades $A_{II}$ que façam conexão com a resposta em questão. A comunicação bidirecional permite a existência de \textit{Feedback} da resposta para as unidades $A_{II}$ com as quais se comunica; e podem ser (a) excitatórias para todas as células de seu conjunto de origem ou (b) inibitórias para todas as células que não transmitam para a resposta em questão.

A partir de uma perspectiva mais contemporânea, o Perceptron passou a ser retratado de uma forma menos abstrata, utilizando funções algébricas explícitas e bem definidas, o que justifica, inclusive, a utilização de uma ilustração mais objetiva, assim como a representada pela Figura \ref{fig:ann_perceptron_new_organization}. Mas vale lembrar que esta nova versão é apenas uma forma diferente de representar artisticamente a mesma estrutura organizacional concebita por Rosenblatt. Não se trata, portanto, de uma real mudança da arquitetura original; apenas é feita uma ilustração que acompanhe uma interpretação sutilmente mais convidativa a partir de um olhar da perspectiva computacional.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.00\textwidth]{figs/ann_perceptron_new_organization.pdf}
    \caption{Representação contemporânea da arquitetura de um \textit{Perceptron}.}
    \label{fig:ann_perceptron_new_organization}
\end{figure}


A partir da Figura \ref{fig:ann_perceptron_new_organization}, pode-se compreender que há um conjunto de entradas, $\bm{x}$, respectivamente ponderadas por um conjunto de pesos, $\bm{w}$, que, junto a um \textit{bias}, são somadas, então o resultado dessa soma é utilizado como entrada de uma \textit{função de ativação}, responsável por emitir o valor da saída, $\bm{y}$. O somatório (também chamado de \textit{campo local induzido} neste contexto) utiliza-se de uma combinação linear causada pela soma ponderada das entradas, além do \textit{bias}, o que resulta na separação de duas regiões por um \textit{hiperplano} \citep{haykin1999neural}, cuja definição matemática é dada por

\begin{equation}
    \nsum_{i=1}^{N} w_{i} x_{i} + b = 0
    \label{eq:ann_perceptron_hyperplane}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent onde $N$ representa o número total de entradas\footnote{O trabalho original de Rosenblatt considerava um arranjo matricial em formato 20x20 em que cada unidade consistia em um sensor fotovoltaico que lia um sinal luminoso e emitia uma resposta de 0 ou 1 quando lia um cartão.} e, portanto, também de seus respectivos pesos para que seja possível efetuar as ponderações; e $b$ representa o \textit{bias}. A partir do resultado do campo local induzido, chega-se à \textit{função de ativação}, a respeito da qual será melhor discutido na seção seguinte.

\pagebreak
\newpage

%   ----- Funções de Ativação -----
\section{Funções de Ativação}
\label{sec:ann_activation_functions}

Um dos elementos mais importantes que compõem um \textit{Perceptron} é a \textit{função de ativação}, que funciona como um filtro que auxilia na tomada de decisões sobre o que fazer com o sinal resultante dos estímulos individuais que a ele chegam, sendo um dos responsáveis finais pela saída a ser obtida. Existem muitos tipos distintos de funções de ativação, não havendo uma função sequer que necessariamente seja melhor que todas as demais em todos os cenários possíveis, o que significa que sempre deverá ser analisado o cenário em questão, quais são os valores possíveis de entrada, quais as saídas desejadas e, também, qual o comportamento da função em toda a região intermediária, afinal, não são apenas os extremos que interferem no desempenho da rede; todos os elementos interferem, embora haja os que possam interferir em maior intensidade.

Essa questão sobre inexistir uma função ideal para todos os cenários é menos óbvia do que parece, assim como em outras áreas do conhecimento também já foram levantadas questões relacionadas, a ponto de que foi preciso realizar um estudo completo para se constatar o que, até então, era mais uma suspeita do que uma constatação da realidade. A mero fim de exemplificação, teoremas de otimização de tipo \textit{não existe almoço grátis} (\textbf{NFL}, \textit{No Free Lunch}) \citep{585893} exibem uma característica bastante similar, pois todo o ganho de desempenho sobre um dado problema acaba sendo ``pago'' na forma de uma perda desempenho sobre ao menos um outro problema, impossibilitando, portanto, que haja uma escolha que seja ótima para todos os casos.

\nomenclature{NFL}{\textit{No Free Lunch}}

Uma das funções mais simples é a função \textit{identidade}, que permite quaisquer valores de entrada e saída, mas não se trata de uma das funções mais exploradas contemporaneamente; na verdade, apesar de sua aparente permissividade, não se trata de uma função muito conveniente. Em vez disso, a função que assume tal posição de prestígio é a função ReLU, que será trazida ainda neste mesmo capítulo. Mas também é importante ressaltar o fato de que a ReLU deu origem a um amplo conjunto de alternativas que são, na verdade, variações dela própria; em muitos casos, variações significativamente sutis, inclusive.

Como o foco deste projeto não são as funções de ativação \textit{Per se}, não será feita uma discussão aprofundada quanto a qualquer uma das funções; contudo, a fim de fornecer um material que possa ser utilizado pelo leitor para visualizar mais facilmente os efeitos de algumas funções de ativação, foram selecionadas algumas das mais comumente exploradas para que sejam aqui matematicamente definidas e tenham seu comportamento exibido graficamente. Dado que uma parte bastante importante do trabalho depende do comportamento de sua derivada, além das próprias funções, os gráficos acompanham os comportamentos de suas respectivas derivadas. Contudo, os gráficos não trazem as mudanças sofridas por tais funções a partir de modificações do \textit{bias}, que é um importante elemento que compõe as operações realizadas ao longo de todos os processos de uma rede neural; ainda assim, a não exibição de tal informação não significa que tais efeitos sejam inócuos, ou mesmo de menor importância; tal decisão foi assim tomada exclusivamente em nome de uma maior clareza na exposição do funcionamento das funções de ativação.

A seguir serão expostos vários exemplos de funções de ativação bastante comuns de serem exploradas em trabalhos desta área.


\begin{figure}[H]
    \centering
    \subfloat[Identidade]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_identity_function.pdf}
        \label{fig:ann_identity_function}
    }
    \subfloat[Degrau]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_unit_step_function.pdf}
        \label{fig:ann_step_function}
    }
    \subfloat[Logística]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_logistic_function.pdf}
        \label{fig:ann_logistic_function}
    }
    \\
    % \vspace{0.5cm}
    \subfloat[Tangente Hiperbólica]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_tanh_function.pdf}
        \label{fig:ann_tanh_function}
    }
    \subfloat[Arco Tangente]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_arctan_function.pdf}
        \label{fig:ann_arctan_function}
    }
    \subfloat[ReLU]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_relu_function.pdf}
        \label{fig:ann_relu_function}
    }
    \\
    % \vspace{0.5cm}
    \subfloat[Leaky ReLU]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_lrelu_function.pdf}
        \label{fig:ann_lrelu_function}
    }
    \subfloat[ISRLU]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_isrlu_function.pdf}
        \label{fig:ann_isrlu_function}
    }
    % \hspace{0.01cm}
    \subfloat[Softplus]
    {
        \includegraphics[width=0.33\textwidth]{figs/ann_softplus.pdf}
        % \label{fig:ann_tanh_function}
    }
    \caption{Exemplos de funções de ativação acompanhadas da primeira derivada.}
    \label{fig:results_mnist}
\end{figure}



Duas funções de ativação serão exploradas neste trabalho: Logística (ou Sigmoidal) e Tangente Hiperbólica; ambas serão trazidas a seguir.



\linebreak
\newpage


\begin{definition}[Função Logística (Sigmoidal)]
    Dada uma entrada $x$, a função Logística pode ser definida como:

    \begin{equation}
        f(x) = \sigma (x) = \dfrac{1}{1 + e^{-x}}
        \vspace{0.2cm}
        \label{eq:ann_logistic_function}
    \end{equation}

    A derivada da função logística é:

    \begin{equation}
        f'(x) = f(x)\ (1 - f(x))
        \label{eq:ann_logistic_function_dy}
    \end{equation}
    
\end{definition}

A Figura \ref{fig:ann_logistic_function} exibe o comportamento da função logística, também conhecida como Sigmoidal.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_logistic_function.pdf}

    \caption{Comportamento da função logística.}
    \label{fig:ann_logistic_function}
\end{figure}





\linebreak
\newpage


\begin{definition}[Função Tangente Hiperbólica]
    Dada uma entrada $x$, a função Tangente Hiperbólica pode ser definida como:

    \begin{equation}
        f(x) = \text{tanh}(x) = \dfrac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
        \vspace{0.2cm}
        \label{eq:ann_tanh_function}
    \end{equation}

    A derivada da função tangente hiperbólica é:

    \begin{equation}
        f'(x) = 1 - (f(x))^{2}
        \label{eq:ann_tanh_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_tanh_function} exibe o comportamento da função tangente hiperbólica e de sua derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_tanh_function.pdf}

    \caption{Comportamento da função tangente hiperbólica.}
    \label{fig:ann_tanh_function}
\end{figure}








% \pagebreak
% \newpage

% \begin{definition}[Função Identidade]
%     Dada uma entrada $x$, a função Identidade pode ser definida como:

%     \begin{equation}
%         f(x) = x
%         \vspace{0.2cm}
%         \label{eq:ann_identity_function}
%     \end{equation}

%     A derivada da função identidade é:

%     \begin{equation}
%         f'(x) = 1
%         \label{eq:ann_identity_function_dy}
%     \end{equation}
    
% \end{definition}

% A Figura \ref{fig:ann_identity_function} exibe o comportamento da função identidade, bem com o de sua primeira derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_identity_function.pdf}
%     \caption{Comportamento da função identidade.}
%     \label{fig:ann_identity_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função Degrau Unitário]
%     Dada uma entrada $x$, a função Degrau Unitário, também chamada de função Degrau Binário, pode ser definida como:

%     \begin{equation}
%         f(x) = u(x) = 
%         \begin{cases}
%             0, & \text{se $x < 0$}\\
%             1, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_step_function}
%     \end{equation}

%     A derivada da função degrau unitário é:

%     \begin{equation}
%         f'(x) = u(x) = 
%         \begin{cases}
%             0, & \text{se $x \neq 0$}\\
%             \text{?}, & \text{se $x = 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_step_function_dy}
%     \end{equation}
    
% \end{definition}

% A Figura \ref{fig:ann_step_function} exibe o comportamento da função degrau unitário (ou binário) e sua primeira derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_unit_step_function.pdf}
%     \caption{Comportamento da função degrau unitário.}
%     \label{fig:ann_step_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função Logística]
%     Dada uma entrada $x$, a função Logística pode ser definida como:

%     \begin{equation}
%         f(x) = \sigma (x) = \dfrac{1}{1 + e^{-x}}
%         \vspace{0.2cm}
%         \label{eq:ann_logistic_function}
%     \end{equation}

%     A derivada da função logística é:

%     \begin{equation}
%         f'(x) = f(x)\ (1 - f(x))
%         \label{eq:ann_logistic_function_dy}
%     \end{equation}
    
% \end{definition}

% A Figura \ref{fig:ann_logistic_function} exibe o comportamento da função logística.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_logistic_function.pdf}

%     \caption{Comportamento da função logística.}
%     \label{fig:ann_logistic_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função Tangente Hiperbólica]
%     Dada uma entrada $x$, a função Tangente Hiperbólica pode ser definida como:

%     \begin{equation}
%         f(x) = \text{tanh}(x) = \dfrac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
%         \vspace{0.2cm}
%         \label{eq:ann_tanh_function}
%     \end{equation}

%     A derivada da função tangente hiperbólica é:

%     \begin{equation}
%         f'(x) = 1 - (f(x))^{2}
%         \label{eq:ann_tanh_function_dy}
%     \end{equation}

% \end{definition}

% A Figura \ref{fig:ann_tanh_function} exibe o comportamento da função tangente hiperbólica e de sua derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_tanh_function.pdf}

%     \caption{Comportamento da função tangente hiperbólica.}
%     \label{fig:ann_tanh_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função Arco Tangente]
%     Dada uma entrada $x$, a função Arco Tangente pode ser definida como:

%     \begin{equation}
%         f(x) = \text{tan}^{-1}(x)
%         \vspace{0.2cm}
%         \label{eq:ann_arctan_function}
%     \end{equation}

%     A derivada da função arco tangente é:

%     \begin{equation}
%         f'(x) = \dfrac{1}{x^{2} + 1}
%         \label{eq:ann_arctan_function_dy}
%     \end{equation}

% \end{definition}

% A Figura \ref{fig:ann_arctan_function} exibe o comportamento da função arco tangente com sua derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_arctan_function.pdf}

%     \caption{Comportamento da função arco tangente.}
%     \label{fig:ann_arctan_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função \textit{Rectified Linear Unit} (ReLU)]
%     Dada uma entrada $x$, a função ReLU pode ser definida como:

%     \begin{equation}
%         f(x) =  
%         \begin{cases}
%             0, & \text{se $x < 0$}\\
%             x, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_relu_function}
%     \end{equation}

%     A derivada da função ReLU é:

%     \begin{equation}
%         f'(x) = u(x) = 
%         \begin{cases}
%             0, & \text{se $x < 0$}\\
%             1, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_relu_function_dy}
%     \end{equation}

% \end{definition}

% A Figura \ref{fig:ann_relu_function} exibe o comportamento da função ReLU \citep{nair2010rectified} acompanhado de sua primeira derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_relu_function.pdf}

%     \caption{Comportamento da função ReLU.}
%     \label{fig:ann_relu_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função \textit{Leaky Rectified Linear Unit} (LReLU)]
%     Dada uma entrada $x$, a função LReLU pode ser definida como:

%     \begin{equation}
%         f(x) = 
%         \begin{cases}
%             0.01 x, & \text{se $x < 0$}\\
%             x, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_lrelu_function}
%     \end{equation}

%     A derivada da função LReLU é:

%     \begin{equation}
%         f'(x) = 
%         \begin{cases}
%             0.01, & \text{se $x < 0$}\\
%             1, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_lrelu_function_dy}
%     \end{equation}

% \end{definition}

% A Figura \ref{fig:ann_lrelu_function} exibe o comportamento da função LReLU \citep{maas2013rectifier} e sua primeira derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_lrelu_function.pdf}

%     \caption{Comportamento da função LReLU.}
%     \label{fig:ann_lrelu_function}
% \end{figure}


% \linebreak
% \newpage


% \begin{definition}[Função \textit{Inverse Square Root Rectified Linear Unit} (ISRLU)]
%     Dada uma entrada $x$, a função ISRLU pode ser definida como:

%     \begin{equation}
%         f(x) = 
%         \begin{cases}
%             \dfrac{x}{\sqrt{1 + \alpha x^{2}}}, & \text{se $x < 0$}\\
%             x, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_isrlu_function}
%     \end{equation}

%     A derivada da função ISRLU é:

%     \begin{equation}
%         f'(x) = 
%         \begin{cases}
%             \left(\dfrac{1}{\sqrt{1 + \alpha x^{2}}}\right)^{3}, & \text{se $x < 0$}\\
%             1, & \text{se $x \geq 0$}
%         \end{cases}
%         \vspace{0.2cm}
%         \label{eq:ann_isrlu_function_dy}
%     \end{equation}

% \end{definition}

% A Figura \ref{fig:ann_isrlu_function} exibe a função ISRLU \citep{carlile2017improving} junto à sua primeira derivada.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.65\textwidth]{figs/ann_isrlu_function.pdf}

%     \caption{Comportamento da função ISRLU para $\alpha=1$ (em cima) e $\alpha=3$ (embaixo).}
%     \label{fig:ann_isrlu_function}
% \end{figure}


\linebreak
\newpage


%   ------------------------
%   ----- Propriedades -----
%   ------------------------
\section{Propriedades}
\label{sec:ann_properties}

Uma \textit{rede neural artificial} (\textbf{ANN}, do inglês \textit{Artificial Neural Network}) é uma estrutura composta por neurônios interconectados distribuídos entre múltiplas camadas. Sua origem vem da ideia de imitar a função cerebral. Uma das características mais importantes das ANNs é a capacidade de aprender com ou sem supervisão (referências para análises comparativas), ou seja, as ANNs podem adotar uma abordagem de aprendizado supervisionado ou uma abordagem de aprendizado não supervisionado \citep{haykin1999neural}, dependendo da implementação do algoritmo de acordo com os objetivos do projeto. Independentemente do tipo de rede neural artificial, os princípios básicos permanecem os mesmos; existem camadas de entrada, camadas ocultas e camadas de saída; cada uma delas será explicada em mais detalhes posteriormente. Camadas ocultas são as principais responsáveis pelo aumento da demanda por poder de processamento, pois é onde residem os neurônios que realizam todo o processamento principal da rede.

\nomenclature{ANN}{\textit{Artificial Neural Network}}

Após uma primeira visão ingênua, talvez se imagine que, dado que os principais responsáveis pelo processamento são os neurônios localizados nas camadas intermediárias, o mais adequado seria aumentar sumariamente o número de neurônios para que isso produzisse um agressivo ganho de desempenho na atividade realizada pela rede; contudo, tal decisão seria, muito provavelmente, bastante equivocada e, sem dúvidas, nem um pouco parcimoniosa. Para se obter melhores resultados, portanto, é preciso estudar melhor sobre o funcionamento dos elementos que compõem toda a rede, além de explorar e analisar diferentes arquiteturas que podem ser mais propícias a responder melhor em certos ambientes específicos.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/ann_mlp.pdf}
    \caption{Representação esquemática e genérica de um MLP.}
    \label{fig:ann_mlp}
\end{figure}

O impacto causado pelas redes neurais artificiais se intensificou drasticamente a partir da criação do \textit{Perceptron multicamadas} (\textbf{MLP}, \textit{Multilayer Perceptron}), que consiste em uma classe de redes em que a informação é propagada apenas em uma direção, sendo enviada para a frente da rede, o que é comumente chamado em materiais de literatura em língua inglesa como \textit{Forward Propagation}. A estrutura de um MLP é composta por ao menos duas camadas intermediárias de neurônios, tal como pode ser visto pela Figura \ref{fig:ann_mlp}, o que permite que, em vez de ser projetado um único hiperplano para separar o hiperespaço de amostras a serem classificadas, passe a ser possível obter modelos bem mais flexíveis quanto a essas regiões de fronteira de separação.

\nomenclature{MLP}{\textit{Multilayer Perceptron}}

Já de longa data, os resultados obtidos levavam pesquisadores e desenvolvedores a acreditar que sua estrutura possuía características intrínsecas de alta capacidade de aproximação de modelos e, embora ainda não tivessem sido matematicamente provadas tais características, sua exploração por parte de diversos pesquisadores resultou em muitos importantes avanços na área. Ao fim da década de 1980 foram publicados trabalhos que efetuavam tal prova matemática em relação à sua capacidade de aproximação \citep{cybenko1989approximation, hornik1989multilayer}, embora tenha sido feita com base em funções sigmoidais. Pouco tempo depois foi publicado um trabalho que provava que, na verdade, essa capacidade de aproximação não era oriunda da função de ativação, mas, em vez disso, era advinda da própria estrutura do MLP, cujo fluxo de informação é direcionado para frente \citep{HORNIK1991251}.

Em 2017 foi provado que o Teorema da Aproximação Universal se aplica a redes profundas que utilizem funções de ativação do tipo ReLU quando respeitada a condição de que haja uma largura\footnote{Neste contexto, a largura da rede se refere apenas ao número de camadas intermediárias que a rede em questão possui, independentemente da quantidade de neurônios que cada uma possua ou da forma como os neurônios efetuem a comunicação entre camadas distintas.} mínima de $n+4$ camadas com o objetivo de se aproximar quaisquer funções que sejam Lebesgue integráveis \citep{royden1988real}. Finalmente, ainda no mesmo ano, foi provada essa capacidade de aproximação universal para qualquer função convexa contínua e, desta vez, necessitando apenas de $n+1$ camadas \citep{hanin2017universal}.


%   ----- ARQUITETURAS -----
\section{Arquiteturas}
\label{sec:ann_architectures}


Nesta seção, serão trazidas algumas arquiteturas de redes clássicas já bastante exploradas na literatura, mas que ainda hoje são utilizadas, dado o fato de terem elevados níveis de eficiência e eficácia na solução de diversos problemas, além do fato de que, justamente por já serem bastante conhecidas, seu comportamento pode ser considerado menos imprevisível, o que pode resultar em menor grau de incerteza nas tentativas de se solucionar eventuais problemas que possam surgir durante o projeto das redes; dependendo da complexidade do problema, ajustes, por vezes necessários, podem ser encontrados já implementados sem grandes dificuldades.




%   ----- REDES DE FUNÇÃO DE BASE RADIAL -----
\subsection{Redes de Função de Base Radial}
\label{subsec:ann_rbf_nets}

As redes de \textit{função de base radial}\footnote{Esta linha, embora ainda muito relevante, perdeu, ainda que momentaneamente, o seu brilho por conta dos avanços feitos em relação às redes profundas.} (\textbf{RBF}, \textit{Radial Basis Function}) \citep{broomhead1988radial}, uma das arquiteturas mais clássicas desta área do conhecimento, também plenamente dotada da capacidade da aproximação universal \citep{park1991universal}, segue um padrão diferenciado do que seu nome pode sugerir a partir de uma primeira interpretação ingênua, pois pode-se concluir, erroneamente, que bastaria que as funções de ativação da rede fossem de tipo radial para que a rede pudesse ser classificada como uma rede RBF --- e, para todos os efeitos, dois exemplos meramente ilustrativos de funções de base radial podem ser vistos na Figura \ref{fig:ann_rbf_1} ---, o que não é o caso; tal tipo de rede possui uma topologia própria, cujas características vão muito além de apenas garantir um certo padrão das funções de ativação envolvidas.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.60\textwidth]{figs/ann_rbf_1.pdf}
    \caption{Exemplos de funções de base radial, assumindo-se $\varepsilon=1$.}
    \label{fig:ann_rbf_1}
\end{figure}

Esta rede não é profunda, ou seja, possui uma quantidade de camadas intermediárias bastante limitada, sendo, em geral, apenas uma ou duas; e, além disso, trata-se de um tipo de rede que pode não seguir uma mesma abordagem uniformizada quanto ao paradigma do processo de aprendizagem para todas as camadas, visto que, caso haja duas ou mais camadas, a primeira camada intermediária seguirá um padrão não-supervisionado, enquanto que as demais camadas intermediárias se utilizarão de uma abordagem supervisionada. Possivelmente, o que mais influencia positivamente no desempenho deste tipo de rede para a solução de problemas para os quais estas redes são consideradas altamente convenientes é a quantidade de neurônios da camada não-supervisionada; assim, ganha-se mais em desempenho conforme amplia-se o espaço das características (\textit{Features}).

Devido à forma como camadas supervisionadas funcionam, com suas funções de ativação tendendo a seguir similaridades em relação ao que se observa a partir das entradas da rede, seu \textit{Modus operandi} aproxima-se bastante dos observados pelo algoritmo de classificação por \textit{vizinhos próximos}; por isso, pode-se compreender a rede neural de tipo RBF como um método de \textit{vizinhos próximos supervisionado} \citep{aggarwal2018neural}. A Equação (\ref{eq:ann_rbf_output}) modela o funcionamento da saída da rede RBF:

\begin{equation}
    \varphi \left(\bm{x}\right) = \nsum_{i=1}^{N} \omega_{i}\ h\left(\ \norm{\ \bm{x} - \bm{c}_{i}\ } \right)
    \label{eq:ann_rbf_output}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent com $N$ sendo o número de neurônios da camada intermediária (oculta); $\bm{c}_{i}$ e $\omega_{i}$ são, respectivamente, o vetor centro e o peso sináptico para o neurônio $i$. E, tipicamente, a função de base radial utilizada é Gaussiana

\begin{equation}
    h\left(\ \norm{\ \bm{x} - \bm{c}_{i}\ }\ \right) = \exp{\left(-\ \norm{\ \bm{x} - \bm{c}_{i}\ }^{\ 2}\right)}
    \label{eq:ann_rbf_gaussian}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

A Figura \ref{fig:ann_arch_rbf} ilustra um modelo esquemático de redes neurais com arquitetura RBF. Perceba que não há qualquer necessidade de o número de neurônios da camada intermediária (oculta), $\bm{h(x)}$, da rede ser igual ao número de entradas da rede, $\bm{x}$; a saída, $\bm{y}$, é única neste caso, embora haja casos com múltiplas saídas. Vale ressaltar o fato de que, independentemente do número de neurônios envolvidos na rede, trata-se de uma rede (totalmente) conectada, ou seja, para cada neurônio de uma dada camada há uma conexão com cada um dos neurônios de suas camadas adjcentes; além disso, diferentemente de como ocorre com as MLPs, as RBFs não sofrem com mínimos locais.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.90\textwidth]{figs/ann_arch_rbf.pdf}
    \caption{Modelo esquemático de redes neurais com arquitetura RBF.}
    \label{fig:ann_arch_rbf}
\end{figure}








%   ----- REDES HOPFIELD -----
\subsection{Redes Hopfield}
\label{subsec:ann_hopfield_nets}

Outra arquitetura de rede neural bastante marcante é a rede \textit{Hopfield} \citep{hopfield1982neural}, uma rede de tipo recorrente --- este tipo será melhor explicada à frente --- e com a importante característica de oferecer garantia de convergência na busca por um ponto de mínimo ao realizar um processo de otimização, contudo, não há qualquer garantia quanto a qual será o ponto de mínimo, o que significa que pode se tratar de um mínimo local; ou seja, pode ser que o resultado obtido pelo processo de otimização não seja, de fato, o melhor possível, embora o resultado obtido sugira que tenha sido este o caso.

A Figura \ref{fig:ann_arch_hopfield} ilustra um exemplo esquemático de rede com arquitetura Hopfield para um exemplo com três neurônios. Vale notar o fato de que, de certa forma, diferente do que se espera de um modelo clássico de rede neural, neste modelo pode-se dizer que inexistem camadas intermediárias, exceto por casos de variações desta arquitetura, mas não dela própria. A rede pode ser pensada como um grafo direcionado completamente conectado, com pesos fixos e realimentação (\textit{Feedback}), sendo que cada neurônio recebe a sua própria entrada e o \textit{Feedback} (da saída) de cada um dos outros neurônios; contudo, o neurônio não é realimentado com sua própria saída e os pesos associados a cada realimentação são simétricos.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/ann_arch_hopfield.pdf}
    \caption{Modelo esquemático de redes neurais com arquitetura Hopfield, seguindo um exemplo com três neurônios.}
    \label{fig:ann_arch_hopfield}
\end{figure}

Os neurônios da rede \textit{Hopfield} podem assumir apenas valores regidos por uma parametrização binária para seus estados, que geralmente são 1 ou -1. Assim como foi dito, todos os neurônios estão ponderadamente conectados entre si, ou seja, para cada par de neurônios $i$ e $j$ há um peso associado $\omega_{ij}$, sendo que, por conta da simetria das ponderações, uma das características desta arquitetura, $\omega_{ij} = \omega_{ji}$. O que define o estado do neurônio, ou seja, se o valor a ser assumido será igual a 1 ou a -1, é o seguinte critério:


    \begin{equation}
        s_{i} = 
        \begin{cases}
            +1, & \text{se $\sum\nolimits_{j}\omega_{ij} s_{j} \geq \theta_{i}$}\\
            -1, & \text{caso contrário}
        \end{cases}
        \hspace{0.1cm},
        \vspace{0.2cm}
        \label{eq:ann_arch_hopfield_state}
    \end{equation}

\noindent sendo que $s_{i}$ e $s_{j}$ representam, respectivamente, o estado do neurônio $i$ e o estado do neurônio $j$; $w_{ij}$ indica o peso do neurônio $j$ na conexão com o neurônio $i$; e $\theta_{i}$ é o limiar de estado do neurônio $i$.


%   ----- MÁQUINA DE BOLTZMANN RESTRITA -----
\subsection{Máquina de Boltzmann Restrita}
\label{subsec:ann_boltzmann_machine}

A arquitetura da \textit{máquina de Boltzmann restrita}\footnote{O trabalho que deu origem à RBM atribuiu o nome \textit{Harmonium} a esta arquitetura.} (\textbf{RBM}, \textit{Restricted Boltzmann Machine}) \citep{smolensky1986information} é única e segue um processo não-supervisionado de aprendizagem; trata-se de um modelo probabilístico que utiliza a energia como métrica.

\begin{definition}[Função de Energia da Máquina de Boltzmann]
    Dado o vetor binário aleatório n-dimensional, $\bm{x} \in \{0,1\}^{n}$; a matriz de pesos dos parâmetros do modelo, $U$; e o vetor de parâmetros de  \textit{bias}, a função de energia da máquina de Boltzmann pode ser definida por

    \begin{equation}
        \mathcalboondox{E}\left(\bm{x}\right) = - \bm{x}^{T}\bm{U}\bm{x} - \bm{b}^{T}\bm{x}
        \label{eq:ann_arch_rbm_energy}
    \end{equation}
\end{definition}


Assim, a distribuição de probabilidade conjunta pode ser definida com base na energia da seguinte maneira:

\begin{definition}[Distribuição de Probabilidade Conjunta baseada em Energia]
    A função de partição $Z$ é tipicamente definita como:

    \begin{equation}
        Z = \nsum_{j} g_{j} \exp{\left(-\dfrac{E_{j}}{k_{B} T}\right)}
        \hspace{0.1cm},
        \vspace{0.2cm}
        \label{eq:ann_arch_rbm_partition}
    \end{equation}

    \noindent em que $g_{j}$ representa o grau de degenerescência\footnote{Nível da tendência que um dado objeto pertencente a uma determinada classe apresenta para passar a pertencer a outra classe, que geralmente é de um tipo menos complexo.} do auto-estado de energia $E_{j}$; $k_{B}$ é a constante de Boltzmann; e $T$ é a temperatura. Então, pode-se definir a distribuição de probabilidade conjunta com base na energia da seguinte forma:

    \begin{equation}
        P\left(\bm{x}\right) = \dfrac{\exp{\left(-\mathcalboondox{E\left(\bm{x}\right)}\right)}}{Z}
        \hspace{0.1cm}
        \vspace{0.2cm}
        \label{eq:ann_arch_rbm_prob}
    \end{equation}
\end{definition}

Diferentemente de como ocorre com as \textit{máquinas de Boltzmann}, com uma estrutura mais clássica que segue um modelo de rede completamente conectada, no caso das RBM inexistem conexões que interligam nós de um mesmo nível da rede --- é isto que caracteriza a denominação ``restrita'' ---, ou seja, as entradas não estão conectadas entre si; além disso, a estrutura básica típica de RBM faz uso de uma única camada oculta, mas há suporte para a adição de múltiplas camadas, o que pode culminar em uma abordagem profunda. Para seguir essa abordagem, basta seguir um empilhamento de modo a inserir apenas camadas ocultas uma seguida da outra.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/ann_arch_rbm.pdf}
    \caption{Modelo esquemático de redes neurais com arquitetura RBM.}
    \label{fig:ann_arch_rbm}
\end{figure}

A Figura \ref{fig:ann_arch_rbm} ilustra um modelo esquemático de redes neurais com arquitetura RBM para uma única camada oculta. Vale observar que a forma clássica de se representar tal tipo de rede não explicita o uso das funções de ativação, tampouco explicita a saída como pertencente a uma nova camada da rede; em vez disso, a rede é representada exclusivamente por camadas visíveis e camadas ocultas, que podem ter números distintos de nós (ou neurônios). Caso essa abordagem fosse utilizada, essa mesma rede poderia ser representada meramente pelos nós indicados por $\bm{x}$ e $\bm{h}$.



%   ----- REDES NEURAIS RECORRENTES -----
\subsection{Redes Neurais Recorrentes}
\label{subsec:ann_recurrent_nets}

As \textit{redes neurais recorrentes} (\textbf{RNN}, \textit{Recurrent Neural Networks}) \citep{Rumelhart1986} são modelos cuja estrutura pode ser compreendida como um grafo direcionado que representa uma série temporal. Uma das mais importantes e marcantes características intrínsecas das RNNs é sua persistência, com nós que realizam, sobre si mesmos, procedimentos de ajustes com base em erros de suas próprias saídas. São exemplos de RNNs a arquitetura \textit{Hopfield} e a arquitetura de \textit{memória de longo prazo} (\textbf{LSTM}, \textit{Long Short-Time Memory}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.20\textwidth]{figs/ann_arch_rnn_chunk.pdf}
    \caption{Representação de um pequeno trecho da composição de uma RNN.}
    \label{fig:ann_arch_rnn_chunk}
\end{figure}

A Figura \ref{fig:ann_arch_rnn_chunk} ilustra um pequeno trecho de uma RNN. A representação indicada por $x_{t}$ e por $y_{t}$ com o $t$ subscrito reflete a ideia de sequência temporal que as próprias RNNs carregam, contudo, vale ressaltar que a transformação que o nó de processamento, indicado por $h$, não sofre variações ao longo do tempo. Uma forma diferenciada de ilustrar funcionalmente a mesma estrutura é indicada pela Figura \ref{fig:ann_arch_rnn_multiple}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{figs/ann_arch_rnn_multiple.pdf}
    \caption{Representação expandida de um pequeno trecho da composição de uma RNN.}
    \label{fig:ann_arch_rnn_multiple}
\end{figure}





%   ----- REDES NEURAIS CONVOLUCIONAIS -----
\subsection{Redes Neurais Convolucionais}
\label{subsec:ann_convolutional_nets}

Embora sejam mais tipicamente associadas a casos de redes profundas, as \textit{redes neurais convolucionais} (\textbf{CNN}, \textit{Convolutional Neural Networks}) \citep{fukushima1980neocognitron} também podem ser implementadas em redes com poucas camadas\footnote{Ao dizer ``redes com poucas camadas'', é importante ressaltar que inexiste uma definição formal e amplamente aceita de um limiar que distingue o que é uma rede profunda do que é uma rede rasa. Para alguns, qualquer rede com mais de uma única camada oculta é profunda; para outros, com mais de duas; e há os que exijam quantias bem maiores de camadas para só então classificarem como profundas.}. Trata-se de um tipo de rede bastante explorado, sobretudo em trabalhos de processamento de imagens, embora não se limite a tais aplicações. Uma possível interpretação razoável a respeito desta abordagem é a de que ela permite analisar a informação a partir de diferentes perspectivas, fazendo desdobramentos por meio das convoluções discretas, geralmente, em duas dimensões; esses desdobramentos por vezes conferem uma peculiar independência quanto às típicas necessidades de informações \textit{a priori}, inerentes a tantos outros métodos. Apesar de ser amplamente utilizado, este tipo de rede demanda elevado poder computacional\footnote{Este, aliás, é um dos principais motivos pelos quais a sua ampla adesão foi tão tardia em relação a quando tal modelo foi trazido ao conhecimento do meio; o processamento por GPU foi um dos principais catalisadores da viabilidade do modelo quanto à sua eficiência \citep{OH20041311, doi:10.1162/neco.2006.18.7.1527}.}; ainda assim, não se trata da abordagem mais custosa.

Esse enorme ganho de autonomia que as CNNs possuem, traz consigo maiores flexibilidade e adaptabilidade para o projetista, o que pode ser interpretado como um grande avanço, dado que, pela primeira vez, dependendo do tipo de projeto com o qual se estiver lidando, pode ser possível reduzir as preocupações quanto ao que diz respeito às tratativas \textit{a priori}; ou seja, tudo o que se entende por pré-processamento passa a ter sua importância questionada. Isso não quer dizer que foi encontrada uma solução perfeita para todos casos --- sempre que alguma ideia assim surgir, deve-se procurar lembrar do \textit{No Free Lunch} (\textbf{NFL}) ---, mas quer, sim, dizer que uma abordagem menos cautelosa pode ser feita para algum conjunto de casos.

Contudo, certos questionamentos também foram levantados por conta de todo esse poder aparente. Ainda hoje há dúvidas quanto aos limites de tais estruturas, assim como critica-se o fato de que o grau de abstração que essas redes implementam é suficientemente elevado para que passe a ser impossível de se saber minuciosamente o que a estrutura elaborada realiza fisicamente, o que contribui para que um \textit{Modus operandi} filosoficamente nocivo passe a ser disseminado, que é o de tratar a rede como uma \textit{caixa preta}, que pode ser totalmente abstraída, sugerindo que o que importa é somente a saída obtida dessa caixa. E o problema dessa abordagem é o fato de que o desconhecimento acerca das minúcias do processamento desse sistema pode contribuir para o desenvolvimento de sistemas errôneos que podem, lamentavelmente, ser aderidos por outros pesquisadores, por empresas ou por usuários finais. Atualmente, até mesmo questões éticas tem sido levantadas a respeito da forma de funcionamento dos algoritmos; para que esses questionamentos possam ser honestamente respondidos, é importante que se saiba plenamente o que o algoritmo faz.




% \begin{figure}[H]
%     \centering
%     \includegraphics[width=1.00\textwidth]{figs/gan_dcgan.pdf}
%     \caption{DCGAN}
%     \label{fig:gan_dcgan}
% \end{figure}





%   ---------------------------
%   ----- Backpropagation -----
%   ---------------------------
\section{Backpropagation}
\label{sec:ann_backpropagation}

O funcionamento iterativo do MLP depende da ocorrência de um treinamento que se dá majoritariamente por conta de um processo de otimização de custo, que se trata da redução do erro resultante da rede, composto pelos erros de cada um dos neurônios que compõem a rede. Para que os ajustes possam ser feitos de forma adequada em todos os neurônios, inclusive os que se localizam nas camadas mais distantes do fim da rede, é essencial que haja alguma maneira de levar a eles essa informação sobre o erro; assim, cada neurônio poderá ter seu peso ajustado de forma independente dos demais, sempre com a missão de reduzir o erro final da rede, não especificamente seu próprio erro. Um dos algoritmos mais utilizados para realizar tal tarefa é conhecido como \textit{Backpropagation} \citep{Rumelhart1986, rumelhart1988parallel}.

Em seu livro \textit{Neural Networks: A Comprehensive Foundation} \citep{haykin1999neural}, Simon Haykin demonstra todo o funcionamento, passo a passo, da etapa de treinamento com o uso do algoritmo de \textit{Backpropagation}, com ilustrações e deduções matemáticas detalhadas, explicadas e comentadas. Haykin separa os casos em dois:

\begin{itemize}
    \item \textbf{Caso 1}: Neurônio de camada de saída
    \item \textbf{Caso 2}: Neurônio de camada oculta (intermediária)
\end{itemize}

Para o Caso 1, isoladamente, o cálculo do erro trata-se de um algoritmo supervisionado, dado que, para cada neurônio (de saída) $j$, existe a dependência de um valor desejado $d_{j}(n)$ para que o erro seja calculado. Assim, para os casos de neurônios da camada de saída, dada uma saída $y_{j}(n)$, o erro instantâneo $e_{j}(n)$ na iteração $n$ pode ser calculado por

\begin{equation}
    e_{j}(n) = d_{j}(n) - y_{j}(n)
    \label{eq:ann_instant_neuron_error}
    \hspace{0.1cm}.
    \vspace{0.2cm}
\end{equation}

Note que a Equação (\ref{eq:ann_instant_neuron_error}) independe de qualquer tratamento matemático rebuscado, dado que utiliza-se apenas do valor desejado (de referência) e do valor efetivamente obtido na saída para que o erro seja calculado. Contudo, para o Caso 2, o algoritmo calcula o \textit{gradiente descendente} \citep{cauchy1847methode} e propaga o erro no sentido oposto ao da transmissão da informação processada pela rede, passando por todas as camadas. O algoritmo considera inicialmente que a energia do erro de cada neurônio é igual a $\frac{1}{2}e_{j}^{2}(n)$ e interpreta que a soma de todos esses erros instantâneos resulta na energia total de erro $\mathcalboondox{E}(n)$, calculada como

\begin{equation}
    \mathcalboondox{E}(n) = \dfrac{1}{2}\nsum_{j \in C}e_{j}^{2}(n)
    \label{eq:ann_total_error_energy}
    \vspace{0.2cm}
\end{equation}

\noindent onde $C$ é o conjunto de todos os neurônios da camada de saída. Caso seja feita a soma dos erros instantâneos de todos os neurônios da camada de saída e seja considerada a normalização de $n$ em relação a $N$, que é a o tamanho do conjunto de treinamento, a \textit{energia média do erro quadrático}, também interpretável neste contexto como \textit{erro quadrático médio} (\textbf{LMS}, \textit{Least Mean Square}), é definida como

\nomenclature{LMS}{\textit{Least Mean Square}}

\begin{equation}
    \mathcalboondox{E}_{\text{avg}}(n) = \dfrac{1}{N} \nsum_{n=1}^{N} \mathcalboondox{E}(n)
    \label{eq:ann_avg_squared_error_energy}
    \vspace{0.2cm}
\end{equation}

A função $\mathcalboondox{E}_{\text{avg}}(n)$ é comumente utilizada como \textit{função custo} para se mensurar o desempenho do processo de aprendizagem correspondente a um determinado conjunto de treinamento; é essa a função a ser minimizada ao longo do processo de treinamento, e a cada iteração do treinamento são feitos ajustes sobre os parâmetros livres, como pesos sinápticos e \textit{bias} da rede, como consequência da otimização. O campo local induzido $\upsilon_{j}(n)$, que se trata do somatório observado na Figura \ref{fig:ann_perceptron_new_organization}, é definido como

\begin{equation}
    \upsilon_{j}(n) = \nsum_{i=0}^{m} w_{ji}(n) y_{i}(n)
    \label{eq:ann_induced_local_field}
    \vspace{0.2cm}
\end{equation}

\noindent onde $w_{ij}(n)$ corresponde ao peso sináptico e $y_{i}(n)$ corresponde à saída do neurônio $i$, que nesta etapa é a entrada do campo local induzido $\upsilon_{j}(n)$ referente ao neurônio $j$, que se encontra na camada seguinte\footnote{É muito importante lembrar-se de que, em um contexto geral de MLP, as entradas de cada neurônio devem ser interpretadas como as saídas dos neurônios localizados na camada anterior.} àquela em que se encontra o neurônio $i$, e $m$ é o número de entradas advindas de neurônios da camada anterior, ou seja, excluindo-se o \textit{bias} na contagem. Após ser calculado o campo local induzido $\upsilon_{j}(n)$ do neurônio $j$, a \textit{função de ativação} $\phi_{j}(n)$ o recebe como entrada, o que produzirá a saída deste neurônio, $y_{j}(n)$, que pode ser matematicamente definida como

\begin{equation}
    y_{j}(n) = \varphi_{j}\left(\upsilon_{j}(n)\right)
    \label{eq:ann_neuron_output}
    \vspace{0.2cm}
\end{equation}

Segundo \citep{haykin1999neural}, o \textit{fator de sensibilidade} $\partial \mathcalboondox{E}(n) / \partial w_{ji}(n)$ pode ser representado como uma forma expandida da \textit{regra da cadeia} (do Cálculo)

\begin{equation}
    \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)} = \dfrac{\partial \mathcalboondox{E}(n)}{\partial e_{j}(n)}\ \dfrac{\partial e_{j}(n)}{\partial y_{j}(n)}\ \dfrac{\partial y_{j}(n)}{\partial \varphi_{j}(n)}\ \dfrac{\partial \varphi_{j}(n)}{\partial w_{ji}(n)}
    \label{eq:ann_gradient_chain_rule}
    \vspace{0.2cm}
\end{equation}

\noindent então, para que seja possível chegar ao valor, é necessário calcular cada uma das derivadas parciais envolvidas na Equação \ref{eq:ann_gradient_chain_rule}. A partir de derivadas parciais das Equações (\ref{eq:ann_total_error_energy}), (\ref{eq:ann_instant_neuron_error}), (\ref{eq:ann_neuron_output}) e (\ref{eq:ann_induced_local_field}), pode-se chegar aos valores de cada um dos termos da Equação (\ref{eq:ann_gradient_chain_rule}), o que leva a

\begin{equation}
    \setlength{\jot}{10pt}
    \begin{align}
    \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)} & = \left(e_{j}(n)\right)\ \left(-1\right)\ \left(\varphi_{j}'\left(\upsilon_{j}(n)\right)\right)\ \left(y_{i}(n)\right)\\
     & = -e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right) y_{i}(n)
    \end{align}
    \label{eq:ann_backpropagation_partial}
    \hspace{0.1cm}.
    \vspace{0.2cm}
\end{equation}

Assim, utilizando-se a \textit{regra delta}, os ajustes de treinamento da rede podem, então, ser representados matematicamente por

\begin{equation}
    \Delta w_{ji}(n) = - \eta\ \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)}
    \label{eq:ann_delta_rule}
    \vspace{0.2cm}
\end{equation}

\noindent sendo $\eta$ a \textit{taxa de aprendizado} do algoritmo, um parâmetro de entrada do algoritmo a ser escolhido pelo projetista da rede, mas que deve ser cautelosamente escolhida. Taxas mais baixas provocarão alterações mais suaves e, consequentemente, mais lentas ao longo do processo de treinamento; ou outro lado, taxas mais elevadas, apesar de acelerarem o treinamento, resultam em perturbações mais abruptas ao longo do processo. Continuando, então, substituindo-se a Equação (\ref{eq:ann_backpropagation_partial}) em (\ref{eq:ann_delta_rule}), obtém-se

\begin{equation}
    \Delta w_{ji}(n) = -e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right) y_{i}(n)
    \label{eq:ann_gradient_adjust_unfinished}
    \vspace{0.2cm}
\end{equation}

\noindent mas pode-se explorar o \textit{gradiente local} $\delta_{j}(n)$ para simplificar a equação, sendo que tal gradiente é dado por

\begin{equation}
    \setlength{\jot}{10pt}
    \begin{align}
    \delta_{j}(n)   & = - \dfrac{\partial \mathcalboondox{E}(n)}{\partial \upsilon_{j}(n)}\\
                    & = - \dfrac{\partial \mathcalboondox{E}(n)}{\partial e_{j}(n)}\ \dfrac{\partial e_{j}(n)}{\partial y_{j}(n)}\ \dfrac{\partial y_{j}(n)}{\partial \upsilon_{j}(n)}\\
                    & = e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right)
    \end{align}
    \label{eq:ann_backpropagation_gradient}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent desta forma, pode-se reescrever a Equação (\ref{eq:ann_gradient_adjust_unfinished}) com o uso de (\ref{eq:ann_backpropagation_gradient}):

\begin{equation}
    \Delta w_{ji}(n) = \eta\ \delta_{j}(n)\ y_{i}(n)
    \label{eq:ann_gradient_adjust}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent ou seja, a \textit{correção dos pesos} $\Delta w_{ji}(n)$ é diretamente influenciada pela \textit{taxa de aprendizado} $\eta$, pelo \textit{gradiente local} $\delta_{j}(n)$ e pelo sinal de entrada do neurônio $j$, $y_{i}(n)$. 





%   ---------------------------
%   ----- Redes Profundas -----
%   ---------------------------
\section{Redes Profundas}
\label{sec:ann_deep_networks}

Apesar de praticamente todos os tópicos abordados até aqui serem relevantes tanto para \textit{redes neurais rasas}\footnote{Tradução livre do termo \textit{Shallow Neural Networks}, encontrado em alguns dos materiais de consulta para designar as redes não profundas, ou seja, as que possuem apenas uma única camada oculta.} quanto para \textit{redes neurais profundas}, este capítulo abordará mais especificamente as redes profundas, dado que serão elas a serem exploradas neste trabalho. Os termos \textit{rasas} e \textit{profundas}, utilizados para caracterizar a ``profundidade'' da rede, ou seja, a quantidade de camadas ocultas (ou intermediárias) que as ANNs podem possuir em sua arquitetura, são apenas o que se conhece por \textit{Buzz-words}, termos não técnicos amplamente utilizados, neste caso, para designar redes neurais com, respectivamente, poucas camadas ocultas (\textit{rasas}) e várias camadas ocultas (\textit{profundas}). Não há um número exato que defina a quantidade de camadas ocultas necessárias para se chamar uma rede neural de \textit{profunda}.



%   ----- Treinamento -----
\subsection{Treinamento}
\label{subsec:ann_training}

Assim que é criada a rede, ela ainda não está pronta para resolver qualquer problema que seja, pois ainda não se adequou a nada até então. O que faz com que a rede se comporte de um determinado modo é o seu treinamento, que realiza todos os ajustes necessários através de suas otimizações associadas ao longo do processo. Um dos exemplos mais típicos é o do algoritmo \textit{Backpropagation}, abordado na Seção \ref{sec:ann_backpropagation}. Em poucas palavras, o que o \textit{Backpropagation} faz é ajustar os parâmetros da rede de modo a torná-la capaz de aproximar regiões com geometrias mais convenientes. Um processo padrão realizado pela etapa de treinamento é composto por cinco tarefas bem definidas, que são:

\begin{enumerate}
    \item Inicialização dos \textit{pesos sinápticos} $w_{ji}(n)$, dos \textit{biases} $b_j(n)$ e, dependendo de como estiver estruturado o algoritmo, dos \textit{limiares} (\textit{Thresholds}) $\theta_{j}(n)$; \\
    \item Propagação para frente da rede, passando-se por todas as camadas intermediárias, até chegar ao valor obtido na saída da rede; \\
    \item Cálculo da \textit{função custo}, que auxilia na quantificação do quão bom foi o resultado obtido se comparado ao resultado almejado, ou seja, trata-se de uma forma de se constatar o erro da rede na iteração em questão; \\
    \item Propagação para trás da rede, atualizando os parâmetros $w_{ji}(n)$, $b_j(n)$ e $\theta_{j}(n)$ com o uso dos gradientes envolvidos no processo; \\
    \item Repetição das tarefas 2, 3 e 4 até que a função custo tenha sido suficientemente otimizada, porém, com o cuidado para que não ocorram problemas de \textit{Overfitting} ou \textit{Underfitting}.
\end{enumerate}

Além dessas tarefas, que são mais gerais e comuns, há diversas técnicas que almejam melhorar o algoritmo, seja reduzindo o custo computacional, seja atingindo valores melhores em suas métricas de qualidade. Uma técnica bastante eficaz quanto à redução do custo computacional é a de \textit{decaimento de taxa de aprendizado} (\textbf{LRD}, \textit{Learning Rate Decay}), que faz com que a \textit{taxa de aprendizado} seja alterada ao longo das iterações do algoritmo de treinamento, fazendo com que haja uma significativa redução no tempo demandado para que o processo de treinamento seja concluído; \textit{Adam}\footnote{Apenas como curiosidade, segundo os próprios autores declararam em sua publicação original \citep{kingma2014adam}, \textit{Adam} trata-se apenas de uma derivação de \textit{adaptive moment estimation}.} \citep{kingma2014adam} é um dos métodos mais utilizados e realiza uma otimização estocástica, sendo uma alternativa ao \textit{gradiente descendente estocástico} (\textbf{SGD}, \textit{Stochastic Gradient Descent}) \citep{robbins1951stochastic, kiefer1952stochastic}.

\nomenclature{LDR}{\textit{Learning Rate Decay}}
\nomenclature{SGD}{\textit{Stochastic Gradient Descent}}

Para se evitar \textit{Overfitting}, um método bastante explorado é o \textit{Dropout} \citep{srivastava2014dropout}, que aleatoriamente desabilita algumas das conexões interneurais da rede, mas apenas as dos neurônios das camada de entrada ou das camadas ocultas, afinal, se não houvesse alguma conexão com os neurônios da camada de saída, o cálculo do erro ficaria comprometido. Apesar de este algoritmo ser mais comumente utilizado com o objetivo de se diminuir os riscos de \textit{Overfitting}, pode-se interpretá-lo também como um otimizador, dado que ele reduz o custo computacional por conta da diminuição dos cálculos na etapa de treinamento em decorrência da desabilitação de algumas conexões da rede.







%   ----- Inicialização -----
\subsection{Inicialização}
\label{subsec:ann_initialization}

Apesar de ser possível iniciar a partir de diferentes configurações e, ainda assim, obter resultados altamente similares, ou até mesmo idênticos, isso não faz com que o processo de inicialização deva ser interpretado como de menor importância, pois erros podem, sim, ser cometidos nesta etapa; más escolhas podem não ser incócuas ao que se almeja quanto ao desempenho da rede e, principalmente, quanto aos seus objetivos finais.

A inicialização deste processo se dá pela escolha dos valores inicialmente assumidos para os \textit{pesos sinápticos} da rede, $w_{ji}(n)$, e para o \textit{limiar} $\theta_{j}$, que é utilizado para delimitar qual o mínimo valor necessário para que cada neurônio seja ativado, ou seja, para que o valor produzido por si seja levado em consideração pelo neurônio seguinte. Se forem utilizados valores iniciais demasiado elevados, há o risco de saturação, o que, devido a baixos valores de gradientes locais, pode resultar em uma considerável desaceleração do processo de treinamento. Por outro lado, a utilização de valores iniciais muito baixos, dependendo da função de ativação escolhida, pode fazer com que o algoritmo acabe trabalhando em uma região muito plana ao redor da superfície de erro.

Uma das possibilidades seria a de inicializar todos os pesos como sendo iguais a zero, porém essa pode não ser uma boa escolha, dado que isso faria com que a derivada em relação à \textit{função custo} fosse igual para todos os pesos, além do fato de que todas as camadas ocultas passariam a se comportar com base nos mesmos pesos, simetricamente, sendo esta uma realidade que seria preservada ao longo de todas as demais iterações, o que não tornaria o desempenho da rede melhor do que seria se fosse simplesmente linear; ou seja, todo o sentido de se aceitar um enorme aumento do custo computacional para que fosse possível explorar aproximações mais complexas seria perdido.

Outra abordagem seria a de inicializar os valores por meio de sorteios aleatórios; possivelmente, respeitando uma dada \textit{função densidade de probabilidade} (\textbf{PDF}, \textit{Probability Density Function}), como uma distribuição Gaussiana ou uma distribuição uniforme. Aliás, uma das sugestões de inicialização feitas em \citep{haykin1999neural} é justamente a de se utilizar valores aleatórios de média zero e com uma variância apropriadamente selecionada para que os valores sorteados permitam que os resultados caiam em ambas as regiões da \textit{função de ativação} $\varphi_{j}(n)$, mas, preferencialmente, não em seus extremos.

Ainda assim, essas abordagens não são as mais convenientes para a maioria dos casos; e, dada a importância que fora constatada para a escolha apropriada de tais parâmetros, diversas técnicas bem mais rebuscadas foram desenvolvidas ao longo do tempo, tais como a \textit{He Initialization} \citep{he2015delving}, que utiliza-se de uma distribuição normal com média zero e desvio padrão dado por $\sqrt{\ 2\ / \left(N_{\text{\ in}} + N_{\text{\ out}}\right)}$, em que $N_{\text{\ in}}$ e $N_{\text{\ out}}$ são, respectivamente, o número de entradas e o número de saídas do neurônio; e \textit{Xavier} (ou \textit{Glorot}) \textit{Initialization} \citep{glorot2010understanding}, que segue uma distribuição normal com média zero e desvio padrão de $\sqrt{\ 1\ / \left(N_{\text{\ in}} + N_{\text{\ out}}\right)}$.