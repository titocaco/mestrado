% !TEX root = main.tex
\chapter{Simulações e Resultados}
\label{cha:results}

Neste capítulo serão explicados os \textit{datasets}, bem como o ambiente de simulação, que consiste em um conjunto de componentes de \textit{Hardware} e \textit{Software} que compõem o computador onde foram realizadas as simulações, além de cada um dos experimentos, incluindo detalhes sobre suas implementações e resultados extraídos de cada uma das simulações realizadas.



%   ----- DATASETS -----
\section{Datasets}
\label{sec:results_datasets}

Dois \textit{datasets} foram explorados para testar as implementações: \textbf{MNIST}\footnote{\textit{\textbf{M}odified \textbf{N}ational \textbf{I}nstitute of \textbf{S}tandards and \textbf{T}echnology} (\textbf{MNIST}).} \citep{lecun-mnisthandwrittendigit-2010} e \textbf{CIFAR}\footnote{\textit{\textbf{C}anadian \textbf{I}nstitute \textbf{F}or \textbf{A}dvanced \textbf{R}esearch} (\textbf{CIFAR}).} \citep{cifar-dataset}; ambos os \textit{datasets} serão melhor detalhados e explicados a seguir.

O MNIST é um conjunto de dados amplamente utilizado de números manuscritos com 70.000 exemplos (60.000 para o conjunto de treinamento e 10.000 para o conjunto de teste); é uma versão modificada de um subconjunto do conjunto de dados NIST original. Os números foram escritos por 250 escritores diferentes, e os escritores responsáveis pelo conjunto de treinamento não são os mesmos escritores que são responsáveis pelo conjunto de testes. Todas as imagens no MNIST foram normalizadas de uma caixa de 28x28 pixels (resolução) para uma caixa de 20x20 pixels, preservando sua proporção e, como resultado da técnica de \textit{anti-aliasing} (do algoritmo de normalização), elas não são mais preto e branco , mas tons de cinza; o resultado teve seu centro de massa centrado novamente em uma caixa de 28x28 pixels.

Existem versões modificadas do MNIST que usam uma paleta de cores invertidas, tornando o número preto e o plano de fundo branco, mas a essência do conjunto de dados MNIST ainda seria preservada para os fins pretendidos. A Figura \ref{fig:datasets_mnist} mostras algumas amostras do dataset MNIST.

% MNIST
\begin{figure}[H]
    \centering
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_0.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_1.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_2.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_3.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_4.pdf}}
    \\
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_5.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_6.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_7.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_8.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/MNIST/mnist_9.pdf}}
    \caption{Amostras do \textit{dataset} MNIST.}
    \label{fig:datasets_mnist}
\end{figure}


O \textit{dataset} CIFAR-10 é uma variação do CIFAR composto por imagens de veículos e animais que compõem um subconjunto do original \textit{80 Million Tiny Images} \citep{4531741}. Existem 60.000 imagens coloridas de 32x32 distribuídas uniformemente entre 10 classes (50.000 para treinamento e 10.000 para teste). A Figura \ref{fig:datasets_cifar} traz algumas amostras do conjunto de dados CIFAR-10.

%   CIFAR-10
\begin{figure}[H]
    \centering
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_0.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_1.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_2.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_3.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_4.pdf}}\hspace{0.1cm}
    \\
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_5.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_6.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_7.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_8.pdf}}\hspace{0.1cm}
    \subfloat{\includegraphics[width=0.175\textwidth]{figs/CIFAR/cifar_9.pdf}}\hspace{0.1cm}
    \caption{Amostras do \textit{dataset} CIFAR-10.}
    \label{fig:datasets_cifar}
\end{figure}


%   ----- AMBIENTE DE SIMULAÇÃO -----
\section{Ambiente de Simulação}
\label{sec:results_simulation_environment}

A fim de melhorar as condições de reprodutibilidade das simulações realizadas neste trabalho, é importante observar a Tabela \ref{tab:results_pc_specs}, que traz as configurações do ambiente em que todas as simulações foram realizadas.



\begin{table}[H]
    \centering
    \caption{Ambiente de simulação.}
    \begin{tabular}{ll}
        \toprule
        \textbf{Componente} &   \textbf{Descrição}\\
        \midrule
        \rowcolor{mColor1!30}
        Processador         &   Intel Core i5-8600K 3.6 GHz (4.3 GHz Turbo) 6-Core 9 MB Cache\\
        \rowcolor{mColor1!0}
        CPU Cooler          &   Corsair H80i v2 Water Cooler\\
        \rowcolor{mColor1!30}
        Placa Mãe           &   Gigabyte Z370XP SLI\\
        \rowcolor{mColor1!0}
        Memória RAM         &   Corsair Vengeance DDR4 3000 MHz 16 GB (2 
        x 8 GB) C15\\
        \rowcolor{mColor1!30}
        SSD                 &   Kingston UV400 240 GB SATA III\\
        \rowcolor{mColor1!0}
        SSHD                &   Seagate Híbrido Firecuda 2 TB 64 MB Cache 
        SATA III\\
        \rowcolor{mColor1!30}
        Placa de Vídeo      &   EVGA GTX 1080 Ti SC2 11 GB\\
        \rowcolor{mColor1!0}
        Fonte               &   Corsair CS750M\\
        \rowcolor{mColor1!30}
        Sistema Operacional &   Ubuntu Desktop 18.04 LTS 64-bit\\
        \rowcolor{mColor1!0}
        NVidia Driver       &   v418.43\\
        \rowcolor{mColor1!30}
        CUDA                &   v10.1\\
        \rowcolor{mColor1!0}
        CUDNN               &   v7.5\\
        \rowcolor{mColor1!30}
        PyTorch             &   v1.0.1\\
        \bottomrule
    \end{tabular}
    \label{tab:results_pc_specs}
\end{table}

A respeito do processador, apesar de a frequência de operação de 4.3 GHz ser atingida apenas por meio da função Turbo, essa função pode ficar ativada sempre que o processador detectar uma demanda por alto poder de processamento, o que pode ocorrer durante todo o período de processamento da simulação. A refrigeração da CPU foi feita por meio de uma solução relativamente poderosa, assim como a fonte utilizada possui capacidades consideravelmente superiores às demandadas, além de ser altamente estável e suficientemente eficiente; isso garantiu que nenhum dos resultados tenha sofrido interferências negativas por conta de qualquer questão inesperada e atípica relacionada ao \textit{Hardware}. Apesar de o computador possuir um SSHD, que é uma solução híbrida, o sistema operacional, os programas utilizados e todos os arquivos dos \textit{datasets} localizavam-se no SSD; o SSHD foi apenas utilizado para fins de \textit{Backup}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.70\textwidth]{figs/htop.png}
    \caption{Monitor de recursos HTOP}
    \label{fig:results_htop}
\end{figure}

Embora o PyTorch ofereça suporte a processamento por GPUs, várias etapas que envolvem processamento somente podem ser efetuadas por CPU, o que, inevitavelmente, faz com que haja um aumento no tempo demandado para concluir toda a simulação. Essa constatação pode ser efetuada por meio de monitores de recursos do sistema operacional e da placa de vídeo; no caso do Ubuntu, eles podem ser acessados por meio dos comandos \textbf{\$ htop} e \textbf{\$ nvidia-smi}, sendo que, caso se deseje visualizar o monitor de recursos da gpu com um intervalo de atualização de 1 segundo, pode-se utilizar o comando \textbf{\$ watch -n 1 nvidia-smi}. Exemplos de ambas as ferramentas de monitoramento de recursos podem ser vistas nas Figuras \ref{fig:results_htop} e \ref{fig:results_nvidia-smi}.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.70\textwidth]{figs/nvidia-smi.png}
    \caption{Monitor de recursos NVIDIA-SMI}
    \label{fig:results_nvidia-smi}
\end{figure}


A utilização de ferramentas de monitoramento de recursos se faz necessária para que seja possível averiguar a existência de qualquer eventual tarefa que, por qualquer razão que seja, esteja se utilizando dos recursos da máquina de modo a colocar em risco o desempenho da simulação. Diferentemente do que talvez se possa imaginar, atrapalhar a simulação não necessariamente significa apenas atrasar o término do processamento; em vez disso, pode significar eventuais alterações no comportamento do programa, o que poderia colocar em risco a veracidade dos resultados obtidos. Dito isso, é importante afirmar que nenhum comportamento maligno foi detectado ao longo das simulações.



%   ----- SIMULAÇÕES PRELIMINARES -----
\section{Simulações Preliminares}
\label{sec:results_preliminary_simulations}

Compreendendo e seguindo as etapas da publicação de Ian Goodfellow sobre GANs \citep{NIPS2014_5423}, uma versão primária do código foi escrita em linguagem Python sobre o Jupyter Notebook a partir do algoritmo publicado no artigo em questão.

Nenhum dos conjuntos de dados mencionados vem pronto para ser usado em um formato conveniente, por isso foi necessário prepará-los para serem utilizados. Com os conjuntos de dados já preparados, foi necessário definir as funções responsáveis pela escolha das amostras que deveriam ser utilizadas nos treinamentos e testes. Todas as implementações de aprendizado profundo que usaram tensores foram feitas usando \textbf{PyTorch} \citep{paszke2017pytorch} e \textbf{TensorFlow} \citep{abadi2016tensorflow}; ambas são bibliotecas, escritas em Python, preparadas para trabalhar com tensores e permitem que o processamento seja executado por Unidades de Processamento Central (CPUs) e Unidades de Processamento Gráfico (GPUs).

É possível escolher se o processo deve priorizar que o processamento seja realizado por CPU ou GPU; este trabalho prioriza a execução por GPU. Tal como fora ressaltado na Seção \ref{sec:gan_for_bss_considerations}, utilizar exclusivamente a CPU para a realização completa de toda e qualquer etapa de processamento envolvida é algo a ser evitado, dado que os arcabouços tratados neste trabalho demandam elevada capacidade de processamento; a paralelização do processamento, que pode ser realizada por meio de GPUs --- sobretudo podendo contar com as facilitadas trazidas por recursos como PyTorch e TensorFlow, que auxiliam o gerenciamento da distribuição do processamento ---, é uma excelente escolha de projeto, principalmente quanto ao tempo demandado para se concluir as tarefas envolvidas. Ainda assim, é importante lembrar que, ao menos até o momento, não há qualquer indicação de que os resultados obtidos ao final do processamento sejam, por si só, afetados pelo meio utilizado para realizar o processamento; isso significa que, ainda que demore bem mais para se concluir o processamento, ignorando-se o tempo gasto, todo o resto do projeto permanece o mesmo.

As redes foram implementadas separadamente; uma classe\footnote{Vale lembrar que o termo \textit{classe} fora aqui utilizado com o objetivo de referir-se a um contexto de programação orientada a objetos.} para o Discriminador, $D$ e outra para o Gerador, $G$. Neste caso, ambas as classes usaram uma rede neural artificial de três camadas ocultas para suas operações. O método de otimização adotado é \textbf{Adam} \citep{kingma2014adam}, que é baseado em estimativas adaptativas de momentos de menor ordem. A etapa de treinamento foi estabelecida com 200 épocas e o conjunto de dados de treinamento foi dividido em 600 lotes de 100 amostras cada.

Dado que o próprio conceito de GAN \textit{per se}, ainda é bastante incipiente, pode ser conveniente trazer algumas simulações que auxiliem na demonstração de sua capacidade. Assim sendo, reproduzindo um dos experimentos realizados por Goodfellow em seu trabalho original sobre as GANs \citep{NIPS2014_5423}, foram treinadas duas redes MLPs, sendo uma rede geradora $\mathcalboondox{G}$ e uma rede discriminadora $\mathcalboondox{D}$, com o objetivo de capturar e reproduzir artificialmente as características intrínsecas do \textit{dataset} MNIST. Esta GAN foi chamada de \textit{Vanilla}, dado que se trata de uma implementação aos moldes seguidos pelo trabalho original de Goodfellow. Trata-se de uma GAN construída com apenas três camadas ocultas de caráter linear, que utilizam-se da \textit{LeakyReLU} como função de ativação; Adam é o método de otimização utilizado, e a rede utiliza-se do algoritmo de \textit{Dropout}; a função de ativação da camada de saída da rede discriminadora é uma simples sigmoidal, enquanto a da rede geradora é uma tangente hiperbólica.




\begin{figure}[H]
    \centering
    \subfloat[Época 1]
    {
        \includegraphics[width=0.30\textwidth]{figs/MNIST/new_tests/_epoch_0_batch_0.png}
        \label{fig:results_mnist_epoch-0}
    }
    \hspace{0.5cm}
    \subfloat[Época 4]
    {
        \includegraphics[width=0.30\textwidth]{figs/MNIST/new_tests/_epoch_3_batch_500.png}
        \label{fig:results_mnist_epoch-3}
    }
    \\
    \vspace{0.5cm}
    \subfloat[Época 33]
    {
        \includegraphics[width=0.30\textwidth]{figs/MNIST/new_tests/_epoch_32_batch_400.png}
        \label{fig:results_mnist_epoch-32}
    }
    \hspace{0.5cm}
    \subfloat[Época 200]
    {
        \includegraphics[width=0.30\textwidth]{figs/MNIST/new_tests/_epoch_299_batch_500.png}
        \label{fig:results_mnist_epoch-299}
    }
    \caption{Gerações da GAN \textit{Vanilla} para o \textit{dataset} MNIST em diferentes épocas.}
    \label{fig:results_mnist}
\end{figure}

A partir da Figura \ref{fig:results_mnist}, pode-se observar o progresso que a GAN obteve ao longo das épocas da simulação. O ponto de partida, observado específicamente na Figura \ref{fig:results_mnist_epoch-0}, trata-se de um ruído Gaussiano branco em todas as figuras. Logo na terceira época, vista na Figura \ref{fig:results_mnist_epoch-3}, já é possível observar o início de algumas formações que se assemelham ao que seriam números 0, 1, 7, 8 e 9, possivelmente, pelo fato de serem estruturas menos complexas do que seriam os demais números, sobretudo os números 0 e 1, visto que podem ser aproximadamente representados como sendo apenas um conjunto de \textit{pixels} espalhados majoritariamente ao longo da vertical, ou em um formato elíptico.

Como pode ser observado pela Figura \ref{fig:results_mnist_epoch-32}, na época 33, algumas figuras começam a esboçar com maior nível de simularidade o que seriam, de fato, estruturas que poderiam ser interpretadas como a de números manuscritos, embora ainda haja elevados níveis de imprecisão e ruídos. Algumas das estruturas observadas chegam a sequer lembrar remotamente qualquer representação numérica que seja. Já ao final do experimento, chegando à época 200, da Figura \ref{fig:results_mnist_epoch-299}, a maior parte das figuras começou a apresentar números manuscritos gerados pela rede com características suficientemente boas para causarem dúvidas quanto à sua autenticidade, ou seja, alguns dos dígitos gerados poderiam ser erroneamente interpretados como sendo oriundos do \textit{dataset} MNIST, embora tenham sido gerados artificialmente.


\begin{figure}[H]
    \centering
    \subfloat[Função custo.]
    {
        \includegraphics[width=0.75\textwidth]{figs/results/cost.pdf}
        \label{fig:results_pytorch_vanilla_mnist_cost}
    }
    \\
    \vspace{0.5cm}
    \subfloat[Probabilidade de a amostra ser considerada legítima.]
    {
        \includegraphics[width=0.75\textwidth]{figs/results/probability.pdf}
        \label{fig:results_pytorch_vanilla_mnist_probability}
    }
    \caption{(a) Função custo e (b) probabilidade de a amostra apresentada à rede discriminadora da GAN \textit{Vanilla}, treinada com o \textit{dataset} MNIST, ser classificada como legítima.}
    \label{fig:results_pytorch_vanilla_mnist_scores}
\end{figure}


Observando-se a Figura \ref{fig:results_pytorch_vanilla_mnist_cost}, pode-se notar que, a função custo sofre um gradual processo de acomodação em torno de 1, sendo que a rede geradora se inicia com um valor mais alto e, exceto por um curto intervalo inicial, decai, quase que suavemente,  até se acomodar a um valor sutilmente inferior a 1; por outro lado, a rede discriminadora, cuja função custo se inicia significativamente abaixo do iniciado pela rede geradora, sofre um momentâneo decaimento nas primeiras épocas, mas logo começa um processo de crescimento, ainda mais suave do que o decaimento observado pela rede geradora, então acomoda-se em uma posição pouco superior a 1. 

A respeito do gráfico da Figura \ref{fig:results_pytorch_vanilla_mnist_probability}, os comportamentos de ambas as redes foi bastante positivo, pois, dado que esse gráfico mostra a chance de uma amostra apresentada à rede discriminadora ser considerada legítima, é esperado que os dados reais se iniciem com alta probabilidade e sofram um decaimento; os dados falsos (gerados pela rede geradora), por sua vez, devem iniciar com probabilidade mais baixa e, ao longo das épocas, terem sua probabilidade aumentada. Para ambos os casos, o desejado é que a probabilidade tenda a se tornar 50\%, pois isso indicaria que a rede discriminadora ficou em dúvida sobre a autenticidade da amostra apresentada. Embora ainda haja uma considerável margem para aprimoramentos, vale ressaltar o fato de que ambas as redes exibiram comportamento dentro do desejado.